{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3035fb",
   "metadata": {},
   "source": [
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d841ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2917b55",
   "metadata": {},
   "source": [
    "### Load Features & Extract Actor IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c763b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1440\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"features.csv\")\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df[\"emotion\"].values\n",
    "\n",
    "# Extract actor-id from stored filename column if available,\n",
    "# otherwise infer from RAVDESS pattern\n",
    "if \"filename\" in df.columns:\n",
    "    filenames = df[\"filename\"].tolist()\n",
    "else:\n",
    "    # optional: store filenames earlier in extraction\n",
    "    filenames = [None] * len(df)\n",
    "\n",
    "def get_actor_id(name):\n",
    "    if name is None:\n",
    "        return 0\n",
    "    return int(name.split(\"-\")[6].split(\".\")[0])\n",
    "\n",
    "groups = [get_actor_id(f) for f in filenames]\n",
    "\n",
    "print(\"Total samples:\", len(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f4c66",
   "metadata": {},
   "source": [
    "### Train-Val-Test Split (70-15-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb526ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1008\n",
      "Val: 216\n",
      "Test: 216\n"
     ]
    }
   ],
   "source": [
    "# First split train (70%) vs temp (30%)\n",
    "X_train, X_temp, y_train, y_temp, groups_train, groups_temp = train_test_split(\n",
    "    X, y, groups,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Split remaining into 15/15 (val/test)\n",
    "X_val, X_test, y_val, y_test, groups_val, groups_test = train_test_split(\n",
    "    X_temp, y_temp, groups_temp,\n",
    "    test_size=0.50,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(X_train))\n",
    "print(\"Val:\", len(X_val))\n",
    "print(\"Test:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92edfc78",
   "metadata": {},
   "source": [
    "### Standardization & Save Scaler   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501693e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(scaler, \"artifacts/standard_scaler.pkl\")\n",
    "print(\"Scaler saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8fdd45",
   "metadata": {},
   "source": [
    "### Baseline Models (Default Parameters), SVM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb92220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline SVM Validation Accuracy: 0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "svm_baseline = SVC(probability=True, random_state=42)\n",
    "svm_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_val_pred_svm_base = svm_baseline.predict(X_val_scaled)\n",
    "\n",
    "baseline_svm_val_acc = accuracy_score(y_val, y_val_pred_svm_base)\n",
    "print(\"Baseline SVM Validation Accuracy:\", baseline_svm_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40da53",
   "metadata": {},
   "source": [
    "### Random Forest Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d46379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF Validation Accuracy: 0.8981481481481481\n"
     ]
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=42)\n",
    "rf_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_val_pred_rf_base = rf_baseline.predict(X_val_scaled)\n",
    "\n",
    "baseline_rf_val_acc = accuracy_score(y_val, y_val_pred_rf_base)\n",
    "print(\"Baseline RF Validation Accuracy:\", baseline_rf_val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3553e0",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e2cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best SVM Params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best SVM CV Score: 0.8091157279029131\n",
      "Tuned SVM Validation Accuracy: 0.9259259259259259\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best RF Params: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best RF CV Score: 0.8695505194017781\n",
      "Tuned RF Validation Accuracy: 0.9120370370370371\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "#----------------------\n",
    "# SVM Grid Search\n",
    "#----------------------\n",
    "\n",
    "svm_param_grid = {\n",
    "    \"C\": [0.1, 1, 10, 100],\n",
    "    \"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.1],\n",
    "    \"kernel\": [\"rbf\", \"linear\"]\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    svm_param_grid,\n",
    "    cv=group_kfold.split(X_train_scaled, y_train, groups_train),\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "print(\"Best SVM Params:\", svm_grid.best_params_)\n",
    "print(\"Best SVM CV Score:\", svm_grid.best_score_)\n",
    "\n",
    "#Validation performance:\n",
    "\n",
    "y_val_pred_svm = best_svm.predict(X_val_scaled)\n",
    "svm_val_acc = accuracy_score(y_val, y_val_pred_svm)\n",
    "print(\"Tuned SVM Validation Accuracy:\", svm_val_acc)\n",
    "\n",
    "#----------------------\n",
    "# RF Grid Search\n",
    "#----------------------\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    cv=group_kfold.split(X_train_scaled, y_train, groups_train),\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "print(\"Best RF Params:\", rf_grid.best_params_)\n",
    "print(\"Best RF CV Score:\", rf_grid.best_score_)\n",
    "\n",
    "#Validation:\n",
    "\n",
    "y_val_pred_rf = best_rf.predict(X_val_scaled)\n",
    "rf_val_acc = accuracy_score(y_val, y_val_pred_rf)\n",
    "print(\"Tuned RF Validation Accuracy:\", rf_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8206026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the best models\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "joblib.dump(best_svm, \"artifacts/svm_model.pkl\")\n",
    "joblib.dump(best_rf, \"artifacts/random_forest_model.pkl\")\n",
    "\n",
    "print(\"Models saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652306d",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece46e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_labels = [\n",
    "\"Neutral\",\"Calm\",\"Happy\",\"Sad\",\n",
    "\"Angry\",\"Fearful\",\"Disgust\",\"Surprised\"\n",
    "]\n",
    "\n",
    "def save_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(9,7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                xticklabels=emotion_labels,\n",
    "                yticklabels=emotion_labels,\n",
    "                cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "save_confusion_matrix(y_val, y_val_pred_svm,\n",
    "    \"Confusion Matrix - SVM (Val)\",\n",
    "    \"artifacts/confusion_svm_val.png\")\n",
    "\n",
    "save_confusion_matrix(y_val, y_val_pred_rf,\n",
    "    \"Confusion Matrix - RF (Val)\",\n",
    "    \"artifacts/confusion_rf_val.png\")\n",
    "svm_report = classification_report(y_val, y_val_pred_svm, target_names=emotion_labels)\n",
    "rf_report = classification_report(y_val, y_val_pred_rf, target_names=emotion_labels)\n",
    "\n",
    "with open(\"artifacts/svm_classification_report.txt\", \"w\") as f:\n",
    "    f.write(svm_report)\n",
    "\n",
    "with open(\"artifacts/rf_classification_report.txt\", \"w\") as f:\n",
    "    f.write(rf_report)\n",
    "\n",
    "print(\"Reports saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f23b7a",
   "metadata": {},
   "source": [
    "### Model comparision Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75df8874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM (Baseline)</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.815173</td>\n",
       "      <td>0.805357</td>\n",
       "      <td>0.801072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF (Baseline)</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.902166</td>\n",
       "      <td>0.895895</td>\n",
       "      <td>0.896706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (Tuned)</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.925260</td>\n",
       "      <td>0.930265</td>\n",
       "      <td>0.926570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF (Tuned)</td>\n",
       "      <td>0.912037</td>\n",
       "      <td>0.915247</td>\n",
       "      <td>0.908826</td>\n",
       "      <td>0.910015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  Precision    Recall        F1\n",
       "0  SVM (Baseline)  0.805556   0.815173  0.805357  0.801072\n",
       "1   RF (Baseline)  0.898148   0.902166  0.895895  0.896706\n",
       "2     SVM (Tuned)  0.925926   0.925260  0.930265  0.926570\n",
       "3      RF (Tuned)  0.912037   0.915247  0.908826  0.910015"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics_summary(y_true, y_pred):\n",
    "    p,r,f,_ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return acc,p,r,f\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append([\"SVM (Baseline)\"] + list(metrics_summary(y_val, y_val_pred_svm_base)))\n",
    "results.append([\"RF (Baseline)\"] + list(metrics_summary(y_val, y_val_pred_rf_base)))\n",
    "results.append([\"SVM (Tuned)\"] + list(metrics_summary(y_val, y_val_pred_svm)))\n",
    "results.append([\"RF (Tuned)\"] + list(metrics_summary(y_val, y_val_pred_rf)))\n",
    "\n",
    "comparison_df = pd.DataFrame(results,\n",
    "    columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "\n",
    "comparison_df.to_csv(\"artifacts/model_comparison.csv\", index=False)\n",
    "\n",
    "comparison_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
